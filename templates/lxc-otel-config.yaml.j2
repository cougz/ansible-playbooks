receivers:
  # Receiver for general system metrics from the host
  hostmetrics:
    collection_interval: 30s
    scrapers:
      cpu:
        metrics:
          system.cpu.utilization: {enabled: true}
      disk:
        metrics:
          system.disk.io: {enabled: true}
      filesystem:
        metrics:
          system.filesystem.usage: {enabled: true}
          system.filesystem.utilization: {enabled: true}
      load:
        metrics:
          system.cpu.load_average.1m: {enabled: true}
          system.cpu.load_average.5m: {enabled: true}
          system.cpu.load_average.15m: {enabled: true}
      memory:
        metrics:
          system.memory.usage: {enabled: true}
          system.memory.utilization: {enabled: true} # Percentage
      network:
        metrics:
          system.network.io: {enabled: true}
          system.network.packets: {enabled: true}
          system.network.errors: {enabled: true}
          system.network.dropped: {enabled: true}
      processes:
        metrics:
          system.processes.count: {enabled: true}

  # Receiver for LXC metrics from your custom script
  prometheus_exec:
    command: "{{ lxc_metrics_script_path }}" # Path to your script, defined in playbook vars
    scrape_interval: "{{ lxc_metrics_scrape_interval | default('30s') }}"
    # Removed: 'env' section. All resource labels are now managed by the 'resource' processor.

  # OTLP receiver for applications or other telemetry sources
  otlp:
    protocols:
      grpc:
        endpoint: "0.0.0.0:4317"
      http:
        endpoint: "0.0.0.0:4318"

processors:
  # Memory limiter to prevent the collector from using too much memory
  memory_limiter:
    check_interval: 5s
    limit_percentage: 75 # Percentage of total host memory
    spike_limit_percentage: 20 # Additional burst capacity

  # Resource processor to add common identifying attributes to all telemetry
  resource:
    attributes:
      # Standard OpenTelemetry Semantic Conventions
      - key: service.name # Application name
        value: "YOUR_LXC_SERVICE_NAME_HERE" # YOU MUST MANUALLY UPDATE THIS
        action: upsert
      - key: service.instance.id # Unique ID for this instance of the service/LXC
        value: "{{ ansible_hostname }}-YOUR_LXC_CTID_HERE" # YOU MUST MANUALLY UPDATE THE CTID PART
        action: upsert
      - key: host.name # Hostname of the LXC (comes from Ansible facts)
        value: "{{ ansible_hostname }}"
        action: upsert
      - key: os.type
        value: "linux"
        action: upsert
      - key: container.runtime
        value: "lxc"
        action: upsert
      - key: container.id # Numeric LXC Container ID
        value: "YOUR_LXC_CTID_HERE" # YOU MUST MANUALLY UPDATE THIS
        action: upsert
      - key: container.name # Friendly name for the container (comes from Ansible facts)
        value: "{{ ansible_hostname }}"
        action: upsert

      # Custom attributes for LXC specific information
      - key: lxc.vlan.id # VLAN ID
        value: "YOUR_LXC_VLAN_ID_HERE" # YOU MUST MANUALLY UPDATE THIS
        action: upsert
      - key: lxc.zone # Zone for the LXC
        value: "YOUR_LXC_ZONE_HERE" # YOU MUST MANUALLY UPDATE THIS
        action: upsert

      # Other potentially useful attributes (already present from previous version)
      - key: host.memory.total_bytes
        value: "{{ ansible_memtotal_mb * 1024 * 1024 }}" # Convert MB to Bytes (comes from Ansible facts)
        action: upsert

  # Batch processor to group telemetry data before exporting
  batch:
    timeout: 5s # Max time to wait before sending a batch
    send_batch_size: 512 # Max number of items in a batch

exporters:
  # OTLP exporter to send data to your LGTM stack or other OTLP endpoint
  otlp:
    endpoint: "{{ otel_endpoint }}" # This will come from your Semaphore Survey Variable
    tls:
      insecure: true # For production, set to false and configure TLS properly

  # Debug exporter (optional, prints telemetry to collector logs)
  debug:
    verbosity: basic # Options: basic, normal, detailed

extensions:
  # Health check extension for monitoring collector status
  health_check:
    endpoint: "127.0.0.1:13133"

service:
  extensions: [health_check]
  pipelines:
    metrics:
      receivers: [hostmetrics, prometheus_exec, otlp]
      processors: [memory_limiter, resource, batch]
      exporters: [otlp, debug] # Remove 'debug' for production
    traces:
      receivers: [otlp]
      processors: [resource, batch]
      exporters: [otlp]
    logs:
      receivers: [otlp]
      processors: [resource, batch]
      exporters: [otlp]

  # Collector's own telemetry settings
  telemetry:
    logs:
      level: info # Collector's internal log level
      output_paths: ["{{ otel_log_dir }}/otelcol.log"]
    metrics:
      level: basic # Level of detail for collector's internal metrics
      address: "127.0.0.1:8888" # Endpoint to scrape collector's own metrics
